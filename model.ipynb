{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d990660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6967abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"tokenised_wmt14\")\n",
    "dataset = dataset.with_format(\"torch\") # turns the lists to torch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f544e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 1775,  1245, 13027,  1007,  2988,  1126,  1212,  3902,  1033,  1024,\n",
      "         3823,  1055,  1024,  2893,  2995, 17793,  3085,  1212, 24621, 28891]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([ 1754,  1948,  3633,  1074,  7316,  1484,  1500,  3747,  1165, 17168,\n",
      "         1644, 17319,  1033,  1156,  4890,  2851,  1079])}\n",
      "Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den n√§chsten Tagen.\n",
      "{'input_ids': tensor([3155, 1152, 6021, 9327, 1117, 1212, 9288,   10, 1014, 7415, 7938]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([ 1397,  2984,  4790,  1255,  1139,  1500,  5063,  1373,  2520,  1463,\n",
      "         1139,  1179, 12708])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokeniser = PreTrainedTokenizerFast.from_pretrained(\"./trained_tokeniser\") \n",
    "\n",
    "\n",
    "data1 =dataset[\"train\"][1]\n",
    "print(data1)\n",
    "input_ids_list = data1[\"labels\"]\n",
    "print(tokeniser.decode(input_ids_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba3235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 2449617\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 2062\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1969\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ab4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 46])\n",
      "torch.Size([32, 46])\n",
      "torch.Size([32, 49])\n"
     ]
    }
   ],
   "source": [
    "# The training loop\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# prepare collate_fn\n",
    "collate_fn = DataCollatorForSeq2Seq(tokeniser,padding=True)\n",
    "\n",
    "#prepare the dataloaders:\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset[\"train\"], shuffle=True, batch_size=batch_size,collate_fn=collate_fn)\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    print(input_ids.shape)\n",
    "    print(attention_mask.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    break\n",
    "\n",
    "#Labels shape is different since its matched with the one to one of the decoders output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c07c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
